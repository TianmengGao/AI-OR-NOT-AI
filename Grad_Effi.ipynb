{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMj7Kcr3hRG5YTrBrxGgTDC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeSL2COsjf5v","executionInfo":{"status":"ok","timestamp":1756548166626,"user_tz":-60,"elapsed":24674,"user":{"displayName":"Tianmeng","userId":"12788940450948297274"}},"outputId":"16493975-ab27-4617-c0cd-b6a56fa09181"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import io\n","from tensorflow.keras.models import load_model\n","\n","# Path to the trained model (modify if needed)\n","MODEL_PATH = \"/content/drive/MyDrive/best_efficientnetb0_model_1.h5\"\n","\n","# 1) Load the model without recompiling\n","model = load_model(MODEL_PATH, compile=False)\n","\n","# 2) Print and save the model architecture summary\n","buf = io.StringIO()\n","model.summary(print_fn=lambda x: buf.write(x + \"\\n\"))\n","summary_str = buf.getvalue()\n","\n","print(summary_str)  # print the full summary\n","with open(\"/content/model_summary.txt\", \"w\") as f:\n","    f.write(summary_str)\n","\n","print(\"Model summary saved to /content/model_summary.txt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"7XfIFudykCwq","executionInfo":{"status":"ok","timestamp":1756548174640,"user_tz":-60,"elapsed":6951,"user":{"displayName":"Tianmeng","userId":"12788940450948297274"}},"outputId":"03eb07bf-45e8-4281-cabc-826cd3b7c8b2"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ efficientnetb0 (Functional)     │ (None, 7, 7, 1280)     │     4,049,571 │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d_4      │ (None, 1280)           │             0 │\n","│ (GlobalAveragePooling2D)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_8 (Dense)                 │ (None, 128)            │       163,968 │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_9 (Dense)                 │ (None, 1)              │           129 │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"," Total params: 4,213,668 (16.07 MB)\n"," Trainable params: 164,097 (641.00 KB)\n"," Non-trainable params: 4,049,571 (15.45 MB)\n","\n","\n","Model summary saved to /content/model_summary.txt\n"]}]},{"cell_type":"code","source":["# 1. Imports\n","import os, glob\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model, Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.efficientnet import preprocess_input\n","\n","# 2. Paths and constants\n","IMG_DIR    = \"/content/drive/MyDrive/feature\"                     # directory of images to visualize\n","OUT_DIR    = \"/content/drive/MyDrive/feature_cam_effnetb0\"        # output directory\n","MODEL_PATH = \"/content/drive/MyDrive/best_efficientnetb0_model_1.h5\"  # trained EfficientNetB0 model\n","IMG_SIZE   = (224, 224)\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# 3. Load model\n","base_model = load_model(MODEL_PATH, compile=False)\n","\n","# 4. Backbone and last convolutional layer\n","backbone = base_model.get_layer(\"efficientnetb0\")  # main feature extractor\n","LAST_CONV_NAME = \"top_conv\"                        # last convolutional layer\n","last_conv_layer = backbone.get_layer(LAST_CONV_NAME)\n","\n","# Feature sub-model: input -> (last conv features, backbone output)\n","feat_model = Model(\n","    inputs=backbone.input,\n","    outputs=[last_conv_layer.output, backbone.output],\n","    name=\"effnetb0_feat_model\"\n",")\n","\n","# 5. Rebuild the full forward graph (backbone -> custom head)\n","inp = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), name=\"gradcam_input\")\n","conv_feat_tensor, bb_out = feat_model(inp)\n","\n","x = bb_out\n","attach = False\n","for lyr in base_model.layers:\n","    if attach:\n","        x = lyr(x)\n","    if lyr.name == backbone.name:\n","        attach = True\n","\n","func_model = Model(inputs=inp, outputs=x, name=\"effnetb0_functional_rebuilt\")\n","grad_model = Model(inputs=func_model.input,\n","                   outputs=[conv_feat_tensor, func_model.output])\n","\n","print(f\"Grad-CAM model ready. Last convolutional layer: {LAST_CONV_NAME}\")\n","\n","# 6. Grad-CAM core utilities\n","def make_gradcam_heatmap(img_array, use_logit=False):\n","    \"\"\"Compute Grad-CAM heatmap. Returns (heatmap, probability_of_AI).\"\"\"\n","    with tf.GradientTape() as tape:\n","        conv_out, preds = grad_model(img_array, training=False)\n","        p = preds[:, 0]  # Dense(1, sigmoid) -> probability of AI class\n","        if use_logit:\n","            eps = 1e-7\n","            p = tf.clip_by_value(p, eps, 1 - eps)\n","            target = tf.math.log(p / (1 - p))\n","        else:\n","            target = p\n","    grads = tape.gradient(target, conv_out)\n","    pooled = tf.reduce_mean(grads, axis=(0, 1, 2))\n","    conv_map = conv_out[0]\n","    heatmap = tf.reduce_sum(conv_map * pooled, axis=-1)\n","    heatmap = tf.nn.relu(heatmap)\n","    heatmap = heatmap / (tf.reduce_max(heatmap) + 1e-8)\n","    return heatmap.numpy(), float(p.numpy()[0])\n","\n","def overlay_heatmap(heatmap, bgr_img, alpha=0.45):\n","    \"\"\"Overlay the heatmap on a BGR image.\"\"\"\n","    h, w = bgr_img.shape[:2]\n","    heatmap = cv2.resize(heatmap, (w, h))\n","    heatmap_uint8 = np.uint8(255 * heatmap)\n","    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n","    return cv2.addWeighted(heatmap_color, alpha, bgr_img, 1 - alpha, 0)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tllURyJwkCzj","executionInfo":{"status":"ok","timestamp":1756548178300,"user_tz":-60,"elapsed":1767,"user":{"displayName":"Tianmeng","userId":"12788940450948297274"}},"outputId":"c823065c-b58c-4fd7-cbe5-f960ed481be0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Grad-CAM model ready. Last convolutional layer: top_conv\n"]}]},{"cell_type":"code","source":["# 7. Batch processing: display and save\n","label_map = {0: \"Human\", 1: \"AI\"}\n","allow_ext = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n","img_paths = sorted(glob.glob(os.path.join(IMG_DIR, \"*.*\")))\n","\n","processed = 0\n","for p in img_paths:\n","    if os.path.splitext(p)[1].lower() not in allow_ext:\n","        continue\n","\n","    bgr = cv2.imread(p)\n","    if bgr is None:\n","        print(f\"Skipped: cannot read {p}\")\n","        continue\n","\n","    bgr_resized = cv2.resize(bgr, IMG_SIZE)\n","\n","    ximg = image.img_to_array(cv2.cvtColor(bgr_resized, cv2.COLOR_BGR2RGB))\n","    ximg = np.expand_dims(ximg, axis=0)\n","    ximg = preprocess_input(ximg)  # EfficientNet preprocessing\n","\n","    heatmap, prob_ai = make_gradcam_heatmap(ximg, use_logit=False)\n","    pred_cls = 1 if prob_ai >= 0.5 else 0\n","\n","    cam_bgr = overlay_heatmap(heatmap, bgr_resized, alpha=0.45)\n","\n","    # Prepare for display with matplotlib (expects RGB)\n","    rgb_orig = cv2.cvtColor(bgr_resized, cv2.COLOR_BGR2RGB)\n","    rgb_cam  = cv2.cvtColor(cam_bgr,     cv2.COLOR_BGR2RGB)\n","\n","    # Plot: show and save\n","    plt.figure(figsize=(6.5, 3.2), dpi=200)\n","    plt.subplot(1, 2, 1); plt.imshow(rgb_orig); plt.axis(\"off\"); plt.title(\"Original\", fontsize=9)\n","    plt.subplot(1, 2, 2); plt.imshow(rgb_cam);  plt.axis(\"off\")\n","    plt.title(f\"Grad-CAM - Pred: {label_map[pred_cls]} (AI prob = {prob_ai:.2f})\", fontsize=9)\n","    plt.tight_layout()\n","\n","    out_name = os.path.splitext(os.path.basename(p))[0] + \"_cam_effnetb0.jpg\"\n","    out_path = os.path.join(OUT_DIR, out_name)\n","    plt.savefig(out_path, bbox_inches=\"tight\")\n","    plt.show()\n","    plt.close()\n","\n","    processed += 1\n","    print(f\"Saved: {out_path}\")\n","\n","print(f\"Done. Exported and displayed {processed} EfficientNetB0 Grad-CAM images to {OUT_DIR}.\")\n"],"metadata":{"id":"-qYw8MjTkC3G","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1bTqmCXmogJRqWvuJS-bflSU9D-YSULpt"},"executionInfo":{"status":"ok","timestamp":1756548225080,"user_tz":-60,"elapsed":45271,"user":{"displayName":"Tianmeng","userId":"12788940450948297274"}},"outputId":"fb225dcb-23ee-434a-9ee4-234527f232a0"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"Sq2I9HHkkC55"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MVaJJGgrkC9E"},"execution_count":null,"outputs":[]}]}